{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're using TF 1.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "print(\"We're using TF\", tf.__version__)\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data(path = 'train_32x32.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(float) / 255.\n",
    "X_test = X_test.astype(float) / 255.\n",
    "X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "y_train, y_val = y_train[:-10000], y_train[-10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train [shape (50000, 28, 28)] sample patch:\n",
      " [[0.         0.29803922 0.96470588 0.98823529 0.43921569]\n",
      " [0.         0.33333333 0.98823529 0.90196078 0.09803922]\n",
      " [0.         0.33333333 0.98823529 0.8745098  0.        ]\n",
      " [0.         0.33333333 0.98823529 0.56862745 0.        ]\n",
      " [0.         0.3372549  0.99215686 0.88235294 0.        ]]\n",
      "A closeup of a sample patch:\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train [shape %s] sample patch:\\n\" % (str(X_train.shape)), X_train[1, 15:20, 5:10])\n",
    "print(\"A closeup of a sample patch:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And the whole sample:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[1, 15:20, 5:10], cmap=\"Greys\")\n",
    "plt.show()\n",
    "print(\"And the whole sample:\")\n",
    "plt.imshow(X_train[1], cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train [shape (50000,)] 10 samples:\n",
      " [5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train [shape %s] 10 samples:\\n\" % (str(y_train.shape)), y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train_flat = X_train.reshape((X_train.shape[0], -1))\n",
    "print(X_train_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_val_flat = X_val.reshape((X_val.shape[0], -1))\n",
    "print(X_val_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oh = keras.utils.to_categorical(y_train, 10)\n",
    "y_val_oh = keras.utils.to_categorical(y_val, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    # close current session\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    # reset graph\n",
    "    K.clear_session()\n",
    "    # create new session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    s = tf.InteractiveSession(config=config)\n",
    "    K.set_session(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.get_variable(\"W\", shape=(784, 10), dtype=tf.float32, trainable=True) ### tf.get_variable(...) with shape[0] = 784\n",
    "b = tf.get_variable(\"b\", shape=(10,), dtype=tf.float32) ### tf.get_variable(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders for the input data\n",
    "input_X = tf.placeholder(tf.float32, shape=(None, 784)) ### tf.placeholder(...) for flat X with shape[0] = None for any batch size\n",
    "input_y = tf.placeholder(tf.float32, shape=(None, 10))###  tf.placeholder(...) for one-hot encoded true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-dbd7b652c5a8>:9: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute predictions\n",
    "logits = input_X @ W + b ### logits for input_X, resulting shape should be [input_X.shape[0], 10]\n",
    "probas = tf.nn.softmax(logits) ### apply tf.nn.softmax to logits\n",
    "classes = tf.argmax(probas,1) ### apply tf.argmax to find a class index with highest probability\n",
    "\n",
    "# Loss should be a scalar number: average loss over all the objects with tf.reduce_mean().\n",
    "# Use tf.nn.softmax_cross_entropy_with_logits on top of one-hot encoded input_y and logits.\n",
    "# It is identical to calculating cross-entropy on top of probas, but is more numerically friendly (read the docs).\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=input_y, logits=logits))### YOUR CODE HERE ### cross-entropy loss\n",
    "\n",
    "# Use a default tf.train.AdamOptimizer to get an SGD step\n",
    "step = tf.train.AdamOptimizer().minimize(loss) ### optimizer step that minimizes the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder:0\", shape=(?, 784), dtype=float32) is not an element of this graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m             subfeed_t = self.graph.as_graph_element(\n\u001b[0;32m-> 1120\u001b[0;31m                 subfeed, allow_tensor=True, allow_operation=False)\n\u001b[0m\u001b[1;32m   1121\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3606\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3607\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3685\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3686\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3687\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"Placeholder:0\", shape=(?, 784), dtype=float32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7babfb7d6241>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         _, batch_loss = s.run([step, loss], {\n\u001b[1;32m     13\u001b[0m         \u001b[0minput_X\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train_flat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         input_y: y_train_oh[batch_start: batch_start + BATCH_SIZE]})\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mbatch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1121\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             raise TypeError('Cannot interpret feed_dict key as Tensor: ' +\n\u001b[0;32m-> 1123\u001b[0;31m                             e.args[0])\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder:0\", shape=(?, 784), dtype=float32) is not an element of this graph."
     ]
    }
   ],
   "source": [
    "s = reset_tf_session()\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 40\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):  # we finish an epoch when we've looked at all training samples\n",
    "    \n",
    "    batch_losses = []\n",
    "    for batch_start in range(0, X_train_flat.shape[0], BATCH_SIZE):\n",
    "        _, batch_loss = s.run([step, loss], {\n",
    "        input_X: X_train_flat[batch_start: batch_start + BATCH_SIZE],\n",
    "        input_y: y_train_oh[batch_start: batch_start + BATCH_SIZE]})\n",
    "        batch_losses.append(batch_loss)\n",
    "\n",
    "    train_loss = np.mean(batch_losses)\n",
    "    val_loss = s.run(loss, {input_X: X_val_flat, input_y: y_val_oh})  # this part is usually small\n",
    "    train_accuracy = accuracy_score(y_train, s.run(classes, {input_X: X_train_flat}))  # this is slow and usually skipped\n",
    "    valid_accuracy = accuracy_score(y_val, s.run(classes, {input_X: X_val_flat}))  \n",
    "    simpleTrainingCurves.add(train_loss, val_loss, train_accuracy, valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib\n",
    "import pyplot as plt\n",
    "from IPython.display\n",
    "import clear_output, display_html, HTML\n",
    "import contextlib\n",
    "import time\n",
    "import io\n",
    "import urllib\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_and_display_figure(fig, sleep = 0.01):\n",
    "    img_data = io.BytesIO()\n",
    "    fig.savefig(img_data, format = 'jpeg')\n",
    "    img_data.seek(0)\n",
    "    uri = 'data:image/jpeg;base64,'\\ +\n",
    "    urllib.request.quote(base64.b64encode(img_data.getbuffer()))\n",
    "    img_data.close()\n",
    "    clear_output(wait = True)\n",
    "    display_html(HTML('<img src=\"' + uri + '\">'))\n",
    "    time.sleep(sleep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMovieWriter(object):\n",
    "   \"\"\"\n",
    "   Usage example:anim = animation.FuncAnimation(...)\n",
    "   anim.save(None, writer = SimpleMovieWriter(sleep = 0.01))\n",
    "   \"\"\"\n",
    "   def __init__(self, sleep = 0.1):\n",
    "      self.sleep = sleep\n",
    "   def setup(self, fig):\n",
    "      self.fig = fig\n",
    "   def grab_frame(self, ** kwargs):\n",
    "      clear_and_display_figure(self.fig, self.sleep)\n",
    "      @contextlib.contextmanager\n",
    "   def saving(\n",
    "      self,\n",
    "      fig,\n",
    "      * args, **\n",
    "      kwargs\n",
    "   ):\n",
    "       self.setup(fig)\n",
    "       try:\n",
    "           yield self\n",
    "       finally:\n",
    "          pass\n",
    "class SimpleTrainingCurves(object):\n",
    "   def __init__(self, loss_name, metric_name):\n",
    "   (self.fig, (self.ax1, self.ax2)) = plt.subplots(nrows = 1,\n",
    "      ncols = 2, figsize = (12, 4))\n",
    "   self.ax1.set_title(loss_name)\n",
    "   self.ax2.set_title(metric_name)\n",
    "   (self.train_loss_curve, ) = self.ax1.plot([], [], 'r',\n",
    "      label = 'train', lw = 2)\n",
    "   (self.valid_loss_curve, ) = self.ax1.plot([], [], 'g',\n",
    "      label = 'valid', lw = 2)\n",
    "   (self.train_metric_curve, ) = self.ax2.plot([], [], 'r',\n",
    "      label = 'train', lw = 2)\n",
    "   (self.valid_metric_curve, ) = self.ax2.plot([], [], 'g',\n",
    "      label = 'valid', lw = 2)\n",
    "   self.iter = 0\n",
    "   self.y_limits_1 = [None, None]\n",
    "   self.y_limits_2 = [None, None]\n",
    "   plt.close(self.fig)\n",
    "   def _update_y_limits(self, limits, * values):\n",
    "      limits[0] = min(list(values) +\n",
    "         (([limits[0]]\n",
    "            if limits[0]\n",
    "            else [])))\n",
    "   limits[1] = max(list(values) +\n",
    "      (([limits[1]]\n",
    "         if limits[1]\n",
    "         else [])))\n",
    "   def _update_curve(\n",
    "         self,\n",
    "         curve,\n",
    "         value,\n",
    "         label,\n",
    "      ):\n",
    "      (x, y) = curve.get_data()\n",
    "   curve.set_data(list(x) + [self.iter], list(y) + [value])\n",
    "   curve.set_label('{}: {}'.format(label, value))\n",
    "   def _set_y_limits(self, ax, limits):\n",
    "      spread = limits[1] - limits[0]\n",
    "      ax.set_ylim(limits[0] - 0.05 * spread, limits[1] + 0.05 *\n",
    "      spread)\n",
    "   def add(\n",
    "         self,\n",
    "         train_loss,\n",
    "         valid_loss,\n",
    "         train_metric,\n",
    "         valid_metric,\n",
    "      ):\n",
    "   self._update_curve(self.train_loss_curve, train_loss, 'train')\n",
    "   self._update_curve(self.valid_loss_curve, valid_loss, 'valid')\n",
    "   self._update_curve(self.train_metric_curve, train_metric,\n",
    "      'train')\n",
    "   self._update_curve(self.valid_metric_curve, valid_metric,\n",
    "      'valid')\n",
    "   self.ax1.set_xlim(0, self.iter)\n",
    "   self.ax2.set_xlim(0, self.iter)\n",
    "   self._update_y_limits(self.y_limits_1, train_loss, valid_loss)\n",
    "   self._update_y_limits(self.y_limits_2, train_metric,\n",
    "      valid_metric)\n",
    "   self._set_y_limits(self.ax1, self.y_limits_1)\n",
    "   self._set_y_limits(self.ax2, self.y_limits_2)\n",
    "   clear_and_display_figure(self.fig)\n",
    "   self.ax1.legend()\n",
    "   self.ax2.legend()\n",
    "   self.iter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
